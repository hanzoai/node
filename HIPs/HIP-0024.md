# HIP-0024: Universal AI Artifact Format (.ai)

## Summary

This proposal defines a universal `.ai` file format for packaging, distributing, and sharing AI artifacts across the Hanzo and Zoo networks. The format provides a standardized container for model weights, fine-tuning deltas, quantized models, datasets, embeddings, and agent state.

## Motivation

The AI ecosystem currently lacks a unified format for packaging AI artifacts that:
- Works across both Hanzo and Zoo networks
- Supports multiple storage backends (local, HuggingFace, IPFS, P2P swarm)
- Provides content-addressable integrity verification
- Enables easy portability of all AI content types
- Supports node operator storage for distributed hosting

## Specification

### File Structure

The `.ai` format is a ZIP archive with the following structure:

```
artifact.ai
├── _format                 # Magic bytes (HAIF) + version (u32 LE)
├── manifest.json          # File listing with hashes
├── metadata.json          # Artifact metadata
├── data/                  # Primary artifact data
│   ├── weights/           # Model weights (safetensors, bin, etc.)
│   ├── config/            # Model configuration
│   └── tokenizer/         # Tokenizer files
├── delta/                 # Fine-tuning deltas (LoRA, QLoRA, etc.)
├── dataset/               # Training/evaluation datasets
├── embeddings/            # Pre-computed embeddings
├── state/                 # Agent state/memory
└── signatures/            # Cryptographic signatures (optional)
```

### Magic Bytes

- Magic: `HAIF` (Hanzo AI Format)
- Version: u32 little-endian (current: 1)

### Artifact Types

| Type | Description |
|------|-------------|
| `Model` | Complete model (weights + config + tokenizer) |
| `Weights` | Model weights only |
| `QuantizedModel` | Quantized model (GGUF, AWQ, GPTQ, ExL2, BnB, MLX) |
| `Delta` | Fine-tuning delta (LoRA, QLoRA, FullDiff, Adapter, Prefix) |
| `Dataset` | Training or evaluation dataset |
| `Embeddings` | Pre-computed embeddings |
| `VectorStore` | Vector index |
| `AgentState` | Agent memory/state |
| `Tokenizer` | Tokenizer files only |
| `Config` | Configuration only |
| `Checkpoint` | Training checkpoint |

### Storage Backends

The format supports multiple storage backends with automatic fallback:

1. **Local** - Filesystem path
2. **HuggingFace** - HF Hub repository (fallback mirror)
3. **Swarm** - BitTorrent-style P2P distribution (info_hash + peers)
4. **IPFS** - Content-addressed storage (CID)
5. **NodeStorage** - Node operator storage (peer_id + path)

### Content Addressing

All artifacts are content-addressed using Blake3 hashes:
- Individual files are hashed and recorded in manifest
- Total artifact hash computed from sorted file hashes
- Hash verification on load prevents corruption/tampering

### Network Support

The format is designed to work across both networks:
- `HanzoMainnet` / `HanzoTestnet`
- `ZooMainnet` / `ZooTestnet`

Artifacts can specify which networks they're available on.

### Metadata Schema

```json
{
  "id": "uuid",
  "name": "artifact-name",
  "version": "1.0.0",
  "description": "Optional description",
  "artifact_type": "Model",
  "author": "author-name",
  "license": "Apache2",
  "tags": ["llm", "inference"],
  "created_at": "2024-01-01T00:00:00Z",
  "updated_at": "2024-01-01T00:00:00Z",
  "size_bytes": 1000000,
  "content_hash": "blake3-hash",
  "requirements": {
    "min_vram_mb": 8000,
    "gpu_required": true,
    "backends": ["cuda", "metal"]
  },
  "networks": ["HanzoMainnet", "ZooMainnet"],
  "locations": [],
  "dependencies": []
}
```

### Supported Licenses

- MIT, Apache2, GPL3
- Llama2, Llama3, Qwen, Gemma (model-specific)
- CC-BY-4.0, CC-BY-NC-4.0, CC-BY-SA-4.0
- Custom, Proprietary

## Implementation

Reference implementation: `hanzo-ai-format` crate

```rust
use hanzo_ai_format::{AiArtifact, ArtifactType, Storage};

// Create artifact
let artifact = AiArtifact::builder()
    .name("my-model")
    .artifact_type(ArtifactType::Model)
    .add_weights("weights.safetensors", data)
    .build()?;

// Save to .ai file
artifact.save("my-model.ai").await?;

// Multi-backend storage
let storage = Storage::with_hf_fallback("/local/path", hf_token);
storage.store(&artifact, replicate: true).await?;
```

## Rationale

### Why ZIP-based?

- Wide tooling support across platforms
- Efficient random access to individual files
- Compression support (deflate)
- Simple implementation

### Why Blake3?

- Fast (SIMD-optimized)
- Secure (256-bit output)
- Consistent with hanzo-compute swarm protocol (HIP-0023)

### Why Multi-Backend Storage?

- Resilience through redundancy
- HuggingFace fallback for compatibility
- P2P distribution for decentralization
- IPFS for permanent content addressing

## Backwards Compatibility

This is a new format. Existing model files can be packaged into .ai archives using the provided tooling.

## Security Considerations

- Content hashes verify integrity
- Optional cryptographic signatures for authentication
- License enforcement via metadata
- No executable code in artifacts

## Reference Implementation

- Crate: `hanzo-ai-format`
- Location: `hanzo-libs/hanzo-ai-format/`
- Tests: 11 passing

## Related HIPs

- HIP-0023: Decentralized AI Compute Swarm Protocol

## Copyright

Copyright and related rights waived via CC0.
