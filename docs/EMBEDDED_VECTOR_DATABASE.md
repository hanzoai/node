# Hanzo Node Embedded Vector Database

## Overview

Hanzo Node includes **LanceDB** as its default embedded vector database, providing local AI agents and workflows with a powerful multimodal storage and retrieval system without external dependencies.

## Why LanceDB?

### ðŸš€ Native Multimodal Support
- Store and search across **text, images, audio, and 3D** in a single database
- Direct binary storage for images and media without base64 encoding
- Automatic metadata extraction from multimodal content

### ðŸ’¾ True Embedded Database
- **Zero server setup** - runs directly in your application process
- Single-file storage format for easy backup and portability
- No external services or network dependencies required
- Perfect for edge AI and local-first applications

### âš¡ Production-Ready Performance
- **IVF_PQ indexing** for billion-scale vector search
- Sub-millisecond latency for similarity queries
- Columnar storage with Apache Arrow for efficient data access
- Streaming support for large datasets

### ðŸ”§ Developer-Friendly
- Simple API similar to traditional databases
- Automatic schema inference from data
- Support for complex queries combining vector search with filters
- Built-in versioning and time-travel queries

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Hanzo Node Application          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚            hanzo-db Interface           â”‚
â”‚         (Multi-Backend Support)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      LanceDB (Default Backend)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Vectors  â”‚  Images â”‚  Audio   â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  Metadata  â”‚  Binary â”‚  Binary  â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚     Apache Arrow Columnar        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Features

### 1. Vector Search Capabilities
```rust
// Native similarity search with cosine distance
let similar_docs = db.vector_search(
    "embeddings",
    query_vector,
    10,  // top-k results
    Some(json!({
        "category": "technical",
        "date": {"$gte": "2024-01-01"}
    }))
).await?;
```

### 2. Multimodal Storage
```rust
// Store images with vectors and metadata
let image_data = MultimodalData {
    vector: embedding,
    image: raw_image_bytes,
    metadata: json!({
        "source": "user_upload",
        "timestamp": chrono::Utc::now(),
        "tags": ["architecture", "diagram"]
    })
};

db.insert_multimodal("images", &image_data).await?;
```

### 3. Hybrid Search
```rust
// Combine vector similarity with metadata filters
let results = db.hybrid_search(
    "documents",
    text_query,     // Converted to vector internally
    json!({         // SQL-like filters
        "author": "Alice",
        "score": {"$gte": 0.8}
    }),
    10
).await?;
```

### 4. Streaming Large Datasets
```rust
// Stream results for memory-efficient processing
let stream = db.stream_query(
    "large_dataset",
    Some(filter),
    1000  // batch size
).await?;

while let Some(batch) = stream.next().await {
    process_batch(batch)?;
}
```

## Use Cases in Hanzo Node

### 1. Local RAG (Retrieval Augmented Generation)
- Store document chunks with embeddings
- Query relevant context for LLM prompts
- No external vector database needed

### 2. Agent Memory Systems
- Persistent storage of agent interactions
- Semantic search through conversation history
- Context-aware decision making

### 3. Workflow State Management
- Store workflow execution states
- Query similar previous executions
- Learn from historical patterns

### 4. Multimodal AI Applications
- Store images with their embeddings
- Cross-modal search (text â†’ image, image â†’ text)
- Build local CLIP-like applications

## Privacy & Security with NVIDIA TEE

When connected to Hanzo Node with NVIDIA TEE support:

### Tier 3: H100 Confidential Computing
- Encrypted vector operations in GPU memory
- Secure similarity computations
- Protected embedding generation

### Tier 4: Blackwell TEE-I/O
- Full database encryption at rest
- Secure I/O paths for all operations
- Hardware-attested query execution

### Graceful Degradation
```rust
// Automatic fallback based on available hardware
let security_level = db.get_security_tier().await?;
match security_level {
    Tier::Four => {
        // Full TEE-I/O protection
        db.enable_tee_io_mode().await?;
    }
    Tier::Three => {
        // H100 CC mode
        db.enable_gpu_encryption().await?;
    }
    _ => {
        // Standard encryption
        db.enable_at_rest_encryption().await?;
    }
}
```

## Performance Benchmarks

### Local Performance (M2 MacBook Pro)
- **Insert**: 50,000 vectors/second
- **Query** (1M vectors): < 10ms for top-10
- **Storage**: ~40% compression vs raw vectors

### GPU-Accelerated (H100)
- **Insert**: 500,000 vectors/second
- **Query** (1B vectors): < 100ms for top-100
- **Batch operations**: 10x faster than CPU

## Getting Started

### 1. Default Configuration
```rust
// LanceDB is the default - no configuration needed
use hanzo_db::{connect, HanzoDbConfig};

let db = connect(HanzoDbConfig::default()).await?;
```

### 2. Explicit LanceDB Selection
```rust
let config = HanzoDbConfig {
    backend: DatabaseBackend::LanceDB,
    path: Some("./data/vectors".into()),
    ..Default::default()
};

let db = connect(config).await?;
```

### 3. Create Collections
```rust
// Define schema for your data
let schema = json!({
    "vector": {"type": "vector", "dimension": 1536},
    "text": {"type": "string"},
    "metadata": {"type": "json"}
});

db.create_table("documents", schema).await?;
```

### 4. Insert and Search
```rust
// Insert documents with embeddings
let docs = vec![
    Document {
        vector: embedding1,
        text: "Hanzo Node architecture",
        metadata: json!({"category": "technical"})
    },
    // ... more documents
];

db.insert_batch("documents", &docs).await?;

// Search for similar documents
let results = db.vector_search(
    "documents",
    query_embedding,
    5
).await?;
```

## Comparison with Other Backends

| Feature | LanceDB | PostgreSQL+pgvector | Redis | SQLite |
|---------|---------|-------------------|-------|---------|
| **Embedded Mode** | âœ… Native | âŒ Requires server | âŒ Requires server | âœ… Native |
| **Vector Search** | âœ… Native, optimized | âœ… Extension | âš ï¸ Limited | âŒ Not supported |
| **Multimodal** | âœ… Native | âš ï¸ Via BYTEA | âŒ Text only | âŒ Text only |
| **Billion-scale** | âœ… IVF_PQ | âš ï¸ With tuning | âŒ Memory limited | âŒ Not suitable |
| **Zero-config** | âœ… Yes | âŒ No | âŒ No | âœ… Yes |
| **GPU Acceleration** | âœ… Supported | âŒ CPU only | âŒ CPU only | âŒ CPU only |

## Advanced Features

### 1. Time-Travel Queries
```rust
// Query data as it was at a specific time
let historical = db.query_at_timestamp(
    "documents",
    chrono::Utc::now() - chrono::Duration::days(7)
).await?;
```

### 2. Incremental Indexing
```rust
// Build indexes incrementally as data grows
db.create_index("documents", IndexType::IvfPq {
    nlist: 100,
    nprobe: 10,
    pq_dims: 8
}).await?;
```

### 3. Multi-tenancy
```rust
// Isolated collections per tenant
let tenant_db = db.with_namespace("tenant_123");
tenant_db.create_table("private_docs", schema).await?;
```

## Migration from Other Systems

### From Pinecone/Weaviate
```bash
# Use hanzo-migrate tool
hanzo-migrate \
  --from pinecone://api-key@index \
  --to lancedb://./local/vectors \
  --batch-size 1000
```

### From PostgreSQL+pgvector
```bash
hanzo-migrate \
  --from postgresql://user:pass@host/db \
  --to lancedb://./local/vectors \
  --table embeddings
```

## Monitoring & Observability

```rust
// Get database statistics
let stats = db.get_stats().await?;
println!("Total vectors: {}", stats.total_vectors);
println!("Index size: {} MB", stats.index_size_mb);
println!("Query latency p99: {} ms", stats.query_p99_ms);

// Enable query logging
db.enable_query_logging("./logs/queries.log").await?;
```

## Best Practices

1. **Index Strategy**: Create indexes after initial bulk loading
2. **Batch Operations**: Use batch inserts for better performance
3. **Compression**: Enable compression for large datasets
4. **Backup**: Use LanceDB's snapshot feature for consistent backups
5. **Monitoring**: Track query latencies and index sizes

## Conclusion

LanceDB provides Hanzo Node with a powerful, embedded vector database that enables:
- **Local-first AI** without external dependencies
- **Multimodal applications** with native support
- **Production-scale** performance in an embedded package
- **Privacy-preserving** operations with TEE support
- **Developer-friendly** API with minimal configuration

This makes Hanzo Node ideal for building AI agents, RAG systems, and multimodal applications that can run anywhere from edge devices to cloud servers, with or without network connectivity.